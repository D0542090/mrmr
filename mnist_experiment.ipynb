{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(60000, 28 * 28)\n",
    "X_test = X_test.reshape(10000, 28 * 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 38, 43, 105, 255, 253, 253, 253, 253, 253, 174, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 43, 139, 224, 226, 252, 253, 252, 252, 252, 252, 252, 252, 158, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 178, 252, 252, 252, 252, 253, 252, 252, 252, 252, 252, 252, 252, 59, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 109, 252, 252, 230, 132, 133, 132, 132, 189, 252, 252, 252, 252, 59, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 29, 29, 24, 0, 0, 0, 0, 14, 226, 252, 252, 172, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 85, 243, 252, 252, 144, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 88, 189, 252, 252, 252, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 91, 212, 247, 252, 252, 252, 204, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 32, 125, 193, 193, 193, 253, 252, 252, 252, 238, 102, 28, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 45, 222, 252, 252, 252, 252, 253, 252, 252, 252, 177, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 45, 223, 253, 253, 253, 253, 255, 253, 253, 253, 253, 74, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 31, 123, 52, 44, 44, 44, 44, 143, 252, 252, 74, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 15, 252, 252, 74, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 86, 252, 252, 74, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 75, 9, 0, 0, 0, 0, 0, 0, 98, 242, 252, 252, 74, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 61, 183, 252, 29, 0, 0, 0, 0, 18, 92, 239, 252, 252, 243, 65, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 208, 252, 252, 147, 134, 134, 134, 134, 203, 253, 252, 252, 188, 83, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 208, 252, 252, 252, 252, 252, 252, 252, 252, 253, 230, 153, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 49, 157, 252, 252, 252, 252, 252, 217, 207, 146, 45, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 103, 235, 252, 172, 103, 24, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(list(X_train[7, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X_train[7, :].reshape(28, 28), cmap = 'binary', vmin = 0, vmax = 255)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.savefig('sample_image.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. F-statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuele_mazzanti/miniconda3/envs/bda_mck/lib/python3.6/site-packages/sklearn/feature_selection/_univariate_selection.py:114: UserWarning: Features [  0   1   2   3   4   5   6   7   8   9  10  11  16  17  18  19  20  21\n",
      "  22  23  24  25  26  27  28  29  30  31  52  53  54  55  56  57  82  83\n",
      "  84  85 111 112 140 141 168 476 560 644 645 671 672 673 699 700 701 727\n",
      " 728 729 730 754 755 756 757 758 759 780 781 782 783] are constant.\n",
      "  UserWarning)\n",
      "/home/samuele_mazzanti/miniconda3/envs/bda_mck/lib/python3.6/site-packages/sklearn/feature_selection/_univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "f = f_classif(X_train, y_train)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "mi = mutual_info_classif(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuele_mazzanti/miniconda3/envs/bda_mck/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm = LGBMClassifier(\n",
    "    objective = 'multiclass',\n",
    "    metric = 'multi_logloss',\n",
    "    importance_type = 'gain'\n",
    ").fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from boruta import BorutaPy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "boruta = BorutaPy(\n",
    "    estimator = RandomForestClassifier(max_depth = 5), \n",
    "    n_estimators = 'auto', \n",
    "    max_iter = 100\n",
    ").fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. MRMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mrmr import mrmr_classif\n",
    "\n",
    "mrmr = mrmr_classif(pd.DataFrame(X_train), pd.Series(y_train), K = 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "ranking = pd.DataFrame(index = range(X_train.shape[1]))\n",
    "\n",
    "ranking['f'] = pd.Series(f, index = ranking.index).fillna(0).rank(ascending = False)\n",
    "ranking['mi'] = pd.Series(mi, index = ranking.index).fillna(0).rank(ascending = False)\n",
    "ranking['logreg'] = pd.Series(np.abs(logreg.coef_).mean(axis = 0), index = ranking.index).rank(ascending = False)\n",
    "ranking['lightgbm'] = pd.Series(lgbm.feature_importances_, index = ranking.index).rank(ascending = False)\n",
    "ranking['boruta'] = boruta.support_* 1 + boruta.support_weak_ * 2 + (1 - boruta.support_ - boruta.support_weak_) * X_train.shape[1]\n",
    "ranking['mrmr'] = pd.Series(list(range(1, len(mrmr) + 1)) + [X_train.shape[1]] * (X_train.shape[1] - len(mrmr)), index = mrmr + list(set(ranking.index) - set(mrmr))).sort_index()\n",
    "\n",
    "ranking = ranking.replace(to_replace = ranking.max(), value = X_train.shape[1])\n",
    "ranking.to_csv('ranking.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_ncols = 3\n",
    "plt_nrows = 2\n",
    "\n",
    "fig, axs = plt.subplots(plt_nrows, plt_ncols, figsize = (plt_ncols * 4, plt_nrows * 4))\n",
    "\n",
    "for e, (algo, title) in enumerate(\n",
    "    zip(\n",
    "        ['f', 'mi', 'logreg', 'lightgbm', 'boruta', 'mrmr'],\n",
    "        ['F-Statistic', 'Mutual Info', 'Log Reg', 'LightGBM', 'Boruta', 'MRMR']\n",
    "    )):\n",
    "\n",
    "    a = axs[divmod(e, plt_ncols)].imshow(\n",
    "        ranking[algo].to_numpy().reshape(28, 28), \n",
    "        cmap = 'Blues_r', \n",
    "        vmin = ranking.min().min(), \n",
    "        vmax = ranking.max().max()\n",
    "    )\n",
    "    \n",
    "    axs[divmod(e, plt_ncols)].set_title(title, fontsize = 14)\n",
    "    axs[divmod(e, plt_ncols)].set_xticks([])\n",
    "    axs[divmod(e, plt_ncols)].set_yticks([])\n",
    "    \n",
    "fig.savefig('featimpo_heatmap.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Performance on Top Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "algos = ['f', 'mi', 'logreg', 'lightgbm', 'mrmr']\n",
    "ks = [1, 2, 5, 10, 15, 20, 30, 40]\n",
    "\n",
    "accuracy = pd.DataFrame(index = ks, columns = algos)\n",
    "roc = pd.DataFrame(index = ks, columns = algos)\n",
    "\n",
    "for algo in algos:\n",
    "    \n",
    "    for k in ks:\n",
    "    \n",
    "        cols = ranking[algo].sort_values().head(k).index.to_list()\n",
    "                \n",
    "        clf = CatBoostClassifier().fit(\n",
    "            pd.DataFrame(X_train)[cols], pd.Series(y_train),\n",
    "            eval_set = (pd.DataFrame(X_test)[cols], pd.Series(y_test)),\n",
    "            early_stopping_rounds = 20,\n",
    "            verbose = False\n",
    "        )\n",
    "                \n",
    "        accuracy.loc[k, algo] = accuracy_score(\n",
    "            y_true = y_test, y_pred = clf.predict(pd.DataFrame(X_test)[cols]))\n",
    "        roc.loc[k, algo] = roc_auc_score(\n",
    "            y_true = y_test, y_score = clf.predict_proba(pd.DataFrame(X_test)[cols]), multi_class = 'ovr', average = 'macro')\n",
    "        \n",
    "accuracy.to_csv('accuracy.csv', index = True)\n",
    "roc.to_csv('roc.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for algo, label, color in zip(\n",
    "    ['mrmr', 'f', 'mi', 'lightgbm', 'logreg'],\n",
    "    ['MRMR', 'F-statistic', 'Mutual Info', 'LightGBM', 'Log Reg'],\n",
    "    ['orangered', 'blue', 'yellow', 'lime', 'black']):\n",
    "        plt.plot(accuracy.index, accuracy[algo], label = label, color = color, lw = 3)\n",
    "\n",
    "plt.plot(\n",
    "    [1, 40], [pd.Series(y_test).value_counts(normalize = True).iloc[0]] * 2, \n",
    "    label = '[Random]', color = 'grey', ls = '--', lw = 3\n",
    ")\n",
    "\n",
    "plt.legend(fontsize = 13, loc = 'center left', bbox_to_anchor = (1, 0.5))\n",
    "plt.grid()\n",
    "plt.yticks(np.linspace(0, 1, 11), ['{:.0%}'.format(i) for i in np.linspace(0, 1, 11)], fontsize = 13)\n",
    "plt.xticks([1] + list(range(5, 41, 5)), fontsize = 13)\n",
    "plt.xlim(-1, 42)\n",
    "plt.ylim(-.05, 1.05)\n",
    "plt.xlabel('Number of features', fontsize = 13)\n",
    "plt.ylabel('Accuracy', fontsize = 13)\n",
    "plt.savefig('accuracy.png', dpi = 300, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot masked images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "\n",
    "plt_ncols = 3\n",
    "plt_nrows = 1\n",
    "\n",
    "cmap = cm.get_cmap('binary')\n",
    "cmap.set_bad(color = 'red')\n",
    "\n",
    "fig, axs = plt.subplots(plt_nrows, plt_ncols, figsize = (plt_ncols * 4, plt_nrows * 4))\n",
    "\n",
    "for e, i in enumerate([1, 7, 17]):\n",
    "    \n",
    "    axs[e].imshow(\n",
    "        pd.DataFrame(X_train).iloc[i, :].mask(ranking['f'] > 200).to_numpy().reshape(28, 28), \n",
    "        cmap = cmap, vmin = 0, vmax = 255\n",
    "    )\n",
    "    \n",
    "    #axs[divmod(e, plt_ncols)].set_title(title, fontsize = 14)\n",
    "    axs[e].set_xticks([])\n",
    "    axs[e].set_yticks([])\n",
    "    \n",
    "fig.savefig('digits_masked.png', dpi = 300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - bda_mck",
   "language": "python",
   "name": "bda_mck"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
